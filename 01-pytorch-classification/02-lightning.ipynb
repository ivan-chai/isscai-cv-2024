{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9518bf76-57b0-4314-8b3c-45c98719f2e0",
   "metadata": {},
   "source": [
    "# PyTorch Lightning\n",
    "\n",
    "Lightning is a high-level library to work with PyTorch. It reduces the amount of code and allows easy multi-gpu training, mixed-precision training, checkpointing, logging, and many other useful tools.\n",
    "\n",
    "The two main abstractions in Lightning are `LightningModule`, `LightningDataModule` and `Trainer`. The user must specify the first two and use Trainer for training and evaluation.\n",
    "\n",
    "`LightningModule` is an instance of `torch.nn.Module` with additional methods like `configure_optimizers`, `training_step` and `validation_step`.\n",
    "\n",
    "`LightningDataModule` creates dataloaders for training, validation and test parts of the dataset.\n",
    "\n",
    "`Trainer` is usually applied without modification.\n",
    "\n",
    "In this notebook we will reproduce results from the first part by using PyTorch Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13388a-e1f2-46ca-8d96-c921c6d273e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install PyTorch Lightning.\n",
    "# ! pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c7f15-1b26-4546-a14f-b39f47964feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ca9bc3-10b1-4b49-b6fb-20e54e538505",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(pl.LightningDataModule):\n",
    "    def __init__(self, num_workers=4, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        dataset = torchvision.datasets.CIFAR10(root=\"cifar10\", train=True, download=True, transform=self.transform)\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.batch_size,  # The number of images in the batch.\n",
    "            num_workers=self.num_workers,  # The number of concurrent readers and preprocessors.\n",
    "            drop_last=True,  # Drop the truncated last batch during training.\n",
    "            pin_memory=torch.cuda.is_available(),  # Optimize CUDA data transfer.\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataset = torchvision.datasets.CIFAR10(root=\"cifar10\", train=False, download=True, transform=self.transform)\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.batch_size,  # The number of images in the batch.\n",
    "            num_workers=self.num_workers,  # The number of concurrent readers and preprocessors.\n",
    "            pin_memory=torch.cuda.is_available(),  # Optimize CUDA data transfer.\n",
    "        )\n",
    "\n",
    "data_module = Data()\n",
    "x, y = next(iter(data_module.test_dataloader()))  # Test loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d906b6-af33-49bb-a6cb-2c6e15d7b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Module(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # The same model as in Part 1.\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, bias=False, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The same as in Part 1.\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "    # Optimizer is now defined in Module.\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "    # Process batch and compute loss.\n",
    "    def training_step(self, batch):\n",
    "        # No need to call self.train(). Lightning do it.\n",
    "        x, y = batch  # No need to move to GPU. Lightning do it.\n",
    "        logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        self.log(\"train/loss\", loss, prog_bar=True)\n",
    "        with torch.no_grad():\n",
    "            predictions = logits.argmax(1)  # (B).\n",
    "            correct = (predictions == y).sum().item()\n",
    "            accuracy = correct / y.numel()\n",
    "            self.log(\"train/accuracy\", accuracy)\n",
    "        return loss  # No need to manually do optimizer step.\n",
    "\n",
    "    # Log test metrics for each batch.\n",
    "    def test_step(self, batch):\n",
    "        # No need to call self.eval(). Lightning do it.\n",
    "        x, y = batch  # No need to move to GPU. Lightning do it.\n",
    "        logits = self(x)  # (B, 10).\n",
    "        predictions = logits.argmax(1)  # (B).\n",
    "        correct = (predictions == y).sum().item()\n",
    "        accuracy = correct / y.numel()\n",
    "        # Compute accuracy for each batch and compute average at the epochs end.\n",
    "        # This variant is not very accurate, as the last batch can be smaller than the rest.\n",
    "        self.log(\"test/accuracy\", accuracy, on_epoch=True)\n",
    "\n",
    "model = Module()\n",
    "data = Data()\n",
    "trainer = pl.Trainer(max_epochs=10)  # Trainer can choose devices automatically.\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1ccd7-54e6-4d44-a3ff-da31fa5507af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb24fe3-f338-44c9-bcdf-97d61b5a2b3a",
   "metadata": {},
   "source": [
    "**Visualization.** PyTorch Lightning dumps logs for TensorBoard by default. We can visualize it inplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd460c6c-a19f-4798-a875-ff8cb8fab946",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fccc08-d6e7-4576-b545-e9b9f25a86c1",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "1. Implement `validation_step` to log test set metrics after each epoch.\n",
    "2. (Advanced) Add learning rate scheduler to `configure_optimizers` and improve the results. In this case the method must return two values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
