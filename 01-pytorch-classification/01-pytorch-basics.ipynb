{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82ab88dc-5b6d-455b-9696-fe6ed37365d9",
   "metadata": {},
   "source": [
    "# Image classification with PyTorch\n",
    "\n",
    "In this notebook we will:\n",
    "1. remember PyTorch basics\n",
    "2. train a simple neural network with PyTorch\n",
    "3. apply PyTorch Lightning to simplify the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca9dc1-fbed-4306-9a76-7aa1f2ca39e5",
   "metadata": {},
   "source": [
    "## PyTorch Basics\n",
    "\n",
    "PyTorch is like Numpy, but with GPU support and automatic gradient computation.\n",
    "\n",
    "See installation notes: https://pytorch.org/get-started/locally/\n",
    "\n",
    "We also need `torchvision` installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fffaf4-6cd0-4a6d-af1f-7c617d7f833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Torch version is\", torch.__version__)\n",
    "print(\"Device is\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b2181-a6d7-44e7-9f9c-d869fa912e65",
   "metadata": {},
   "source": [
    "**Working with tensors**\n",
    "\n",
    "PyTorch is similar to Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c728fd-644d-45d0-a0d9-2447746c932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([3, 4, 5])  # Create a new tensor (on CPU).\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e1b9e-38c6-49d3-b091-9f5c455993d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f0d2c-7f57-4760-9665-8c66e6044718",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[None]  # Add dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087d445-3fe8-4cca-8507-d7e50b0b893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[None].T  # Transpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114e6a7e-1e46-4550-b973-34f859bf7495",
   "metadata": {},
   "source": [
    "**Working with devices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b41859-2140-4bbd-a0ff-2a00556caaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.to(DEVICE)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cac31b-06c2-4e11-bea0-081f8d570349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a + b  # ERROR if DEVICE is cuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c318920-cd5d-4148-8ca0-a7641e8c7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to(DEVICE) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33be5ec5-47c3-4b8a-88f1-23bfdd5c27d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8667b46-1cb4-49e3-86f7-91e5e60d8ff5",
   "metadata": {},
   "source": [
    "## Gradient computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa35e913-9414-48d4-9e54-97de165358a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.linspace(0, 5, 100, requires_grad=True)  # Allow gradient computation for this tensor.\n",
    "ys = torch.sin(xs)\n",
    "with torch.no_grad():  # Disable computation graph tracking for a while.\n",
    "    plt.plot(xs, ys)\n",
    "\n",
    "ys.sum().backward()  # Compute gradients for each parameter.\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(xs), len(xs) // 10):\n",
    "        grad_value = xs.grad[i]  # Take i-th component of the gradient vector.\n",
    "        plt.arrow(xs[i], ys[i], 1, grad_value, color=\"r\", head_width=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b5dc3-4464-4a61-be3a-ee2b604aa780",
   "metadata": {},
   "source": [
    "# Simple CNN\n",
    "\n",
    "Each model in PyTorch is an instance of `nn.Module`. The base class provides useful tools:\n",
    "1. Moving models between devices, e.g. `model.cuda()` and `model.cpu()`\n",
    "2. Switching model between training and evaluation modes, e.g. `model.train()`, `model.eval()`. It is necessary for the correct BatchNorm and Dropout computation.\n",
    "3. Iteration across model parameters, e.g. `model.parameters()` and `model.named_parameters()`.\n",
    "4. Checkpoint creation and loading, e.g. `model.state_dict()` and `model.load_state_dict()`.\n",
    "\n",
    "`nn.Module` automatically tracks parameters, buffers and submodules. `nn.Parameter` is a tensor wrapper for trainable parameters. Buffers are used to track statistics and can be create by `self.register_buffer()`. Buffers and parameters constitute a model checkpoint. \n",
    "\n",
    "The only required method in `nn.Module` is `forward()`, which applies the model.\n",
    "\n",
    "**Tensor format**\n",
    "\n",
    "PyTorch stores tensors in the (B, C, H, W) format, where B is a batch size, C is a number of channels, H and W are height and width respectively. Notice, that channels is the second dimension, not the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c8312a-a832-46c1-a291-2a2a100ab6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Input is a 32x32 3-channel image, i.e. (B, 3, 32, 32) tensor.\n",
    "        self.layer1 = nn.Sequential(  # Combines multiple layers in a single block.\n",
    "            # Disable bias prior to BatchNorm.\n",
    "            nn.Conv2d(3, 16, 3, bias=False),  # Input: 3 channels, output: 16 channels, kernel size 3.\n",
    "            nn.BatchNorm2d(16),  # 16 is the number of channels.\n",
    "            nn.ReLU(inplace=True)  # Inplace operations, when available, reduce memory usage.\n",
    "        )  # Output is (B, 16, 30, 30). Image size is reduced because there is no padding.\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, bias=False, stride=2),  # Add stride to reduce tensor height and width by a factor of 2.\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )  # Output is (B, 32, 14, 14) because of stride.\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, bias=False, stride=2),  # Add stride to reduce tensor height and width by a factor of 2.\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )  # Output is (B, 64, 6, 6) because of stride.\n",
    "        \n",
    "        # Add fully-connected neural head.\n",
    "        self.head = nn.Sequential(\n",
    "            # Head input is (B, C, H, W).\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),  # (B, C, 1, 1).\n",
    "            nn.Flatten(),  # (B, C).\n",
    "            nn.Linear(64, 10)  # 10 is the number of classes.\n",
    "        )  # Output is (B, 10).\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: (B, 3, 32, 32).\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.head(x)\n",
    "        # Output: (B, 10).\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cbf09d-f314-4675-ac6c-5b9f9d53d8b5",
   "metadata": {},
   "source": [
    "**Create dataset and loader**\n",
    "\n",
    "We will use the standard CIFAR10 dataset from torchvision. CIFAR10 contains small images of 10 classes (ships, airplains etc.). \n",
    "\n",
    "PyTorch dataset is an instance of `torch.utils.data.Dataset` with two methods: `__len__` and `__getitem__`. These methods are sufficient for dataset indexing and iteration.\n",
    "\n",
    "`torch.utils.data.DataLoader` is responsible for the multiprocess data loading and batch collection. It accepts a dataset and loading parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcad109-138e-4474-943b-3d77c3085268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar10_loader(part=\"train\", transform=True):\n",
    "    if part == \"train\":\n",
    "        train = True\n",
    "    elif part == \"test\":\n",
    "        train = False\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset part: {part}\")\n",
    "    # Transform specifies how to create a tensor from an image (usually PIL).\n",
    "    if transform:\n",
    "        transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "        ])\n",
    "    else:\n",
    "        transform = None\n",
    "    dataset = torchvision.datasets.CIFAR10(root=\"cifar10\", train=train, download=True, transform=transform)\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=32,  # The number of images in the batch.\n",
    "        num_workers=4,  # The number of concurrent readers and preprocessors.\n",
    "        drop_last=train,  # Drop the truncated last batch during training.\n",
    "        pin_memory=(DEVICE == \"cuda\"),  # Optimize CUDA data transfer.\n",
    "    )\n",
    "\n",
    "loader = get_cifar10_loader(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa869a-5060-4a6a-8212-8868b8673fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = get_cifar10_loader(\"test\", transform=False).dataset[10]\n",
    "print(\"Example image with label\", label)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2fb6b8-30a9-45ca-ad66-713d46a71565",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(loader))\n",
    "print(\"Input size:\", x.shape)\n",
    "print(\"Input range:\", x.min(), x.max())\n",
    "print(\"Sample labels:\", y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf74d83-a427-4bf3-a00e-22ed99030ce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, loader):\n",
    "    model.train()  # Switch BatchNorm to the training mode.\n",
    "    n = 0\n",
    "    n_correct = 0\n",
    "    for x, y in tqdm(loader):\n",
    "        # x: Images with shape (B, 3, 32, 32).\n",
    "        # y: Labels with shape (B).\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)  # Move data to GPU if necessary.\n",
    "        logits = model(x)  # (B, 10).\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        optimizer.zero_grad()  # Clean previous gradients.\n",
    "        loss.backward()  # Compute gradients.\n",
    "        optimizer.step()  # Update parameters.\n",
    "        # Update metrics.\n",
    "        with torch.no_grad():\n",
    "            predictions = logits.argmax(1)  # (B).\n",
    "            n_correct += (predictions == y).sum().item()  # item() converts tensor to a Python scalar.\n",
    "            n += y.numel()\n",
    "    accuracy = n_correct / n\n",
    "    print(\"Train set accuracy:\", accuracy)\n",
    "    return loss.item(), accuracy\n",
    "\n",
    "\n",
    "def test_epoch(model, loader):\n",
    "    model.eval()  # Switch BatchNorm to the evaluation mode.\n",
    "    n = 0\n",
    "    n_correct = 0\n",
    "    for x, y in tqdm(loader):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)  # Move data to GPU if necessary.\n",
    "        logits = model(x)  # (B, 10).\n",
    "        predictions = logits.argmax(1)  # (B).\n",
    "        n_correct += (predictions == y).sum().item()  # item() converts tensor to a Python scalar.\n",
    "        n += y.numel()\n",
    "    accuracy = n_correct / n\n",
    "    print(\"Test set accuracy:\", accuracy)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train_cifar10(model, optimizer, num_epochs=10):\n",
    "    model.to(DEVICE)\n",
    "    train_loader = get_cifar10_loader(\"train\")\n",
    "    test_loader = get_cifar10_loader(\"test\")\n",
    "    losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"EPOCH\", epoch)\n",
    "        final_loss, final_accuracy = train_epoch(model, optimizer, train_loader)\n",
    "        with torch.no_grad():  # Disable gradient tracking during evaluation.\n",
    "            test_accuracy = test_epoch(model, test_loader)\n",
    "        losses.append(final_loss)\n",
    "        train_accuracies.append(final_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "    return losses, train_accuracies, test_accuracies\n",
    "\n",
    "model = SimpleCNN()\n",
    "# Create Adam optimizer.\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),  # Pass model parameters.\n",
    "    lr=0.001  # Learning rate\n",
    ")\n",
    "losses, train_accuracies, test_accuracies = train_cifar10(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a9c285-c33b-4f77-8ca9-2d62410c1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 3))\n",
    "axs[0].plot(losses)\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_title(\"Train loss\")\n",
    "axs[1].plot(train_accuracies, label=\"Train\")\n",
    "axs[1].plot(test_accuracies, label=\"Test\")\n",
    "axs[1].legend()\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b4d039-3888-4da6-a13c-9b1121c19177",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "1. Implement a new model with `nn.Flatten` instead of `AdaptiveAvgPool2d`.\n",
    "2. Adjust the final linear layer's size accordingly.\n",
    "3. Train the model and compare results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00db24a-0c1c-43d4-956d-f026bbcf9fdb",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "1. Try to use a different optimizer, like SGD.\n",
    "2. Try to adjust optimizer's parameters to improve test set accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
